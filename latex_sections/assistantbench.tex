\subsection{AssistantBench}\label{app:assistantbench}

\paragraph{Benchmark.}
AssistantBench evaluates AI agents on realistic, time-consuming, and automatically verifiable tasks. It consists of 214 tasks that are based on real human needs and require several minutes of human browsing.
Paper: \cite{assistantbench}.

\paragraph{Agents.}
We ran one agent scaffold: Browser-Use. Browser-Use is a python-based browser automation agent that uses playwright to interact with web pages. Its goal is to help automate tasks online. We ran 12 evaluations with 12 different models ranging from Claude-3.7 Sonnet released in February 2025 to GPT-5 released in August 2025.

\begin{table}[t]
  \centering
  \caption{AssistantBench Leaderboard}
  \label{tab:assistantbench_full}
  \input{tables/assistantbench_full_results.tex}
\end{table}


\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.9\linewidth]{ab_pareto_accuracy_vs_cost.pdf}
  \caption{Pareto frontier of accuracy vs.\ cost.}
  \label{fig:ab_pareto}
\end{figure}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.9\linewidth]{ab_total_tokens.pdf}
  \caption{Total completion tokens used per Agent}
  \label{fig:ab_tokens}
\end{figure}

\begin{figure*}[t]
  \centering
  \adjustbox{max width=\textwidth, max height=0.9\textheight}{%
    \includegraphics{ab_heatmap_best_vs_any.pdf}%
  }
  \caption{Heatmap: best-agent vs.\ any-agent success.}
  \label{fig:ab_heatmap}
\end{figure*}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.9\linewidth]{ab_accuracy_vs_release_date.pdf}
  \caption{Accuracy vs.\ model release date.}
  \label{fig:ab_release}
\end{figure}

\clearpage