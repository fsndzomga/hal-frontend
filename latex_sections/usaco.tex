\subsection{USACO}\label{app:usaco}

\paragraph{Benchmark.}
The USACO benchmark evaluates AI agents on competitive programming problems from the USA Computing Olympiad. It consists of 307 problems, complete with exhaustive test cases, problem analyses, and difficulty labels. This benchmark tests agents' ability to solve algorithmic challenges and write efficient code.
Paper: \cite{usaco}.

\paragraph{Agents.}
Briefly describe the two agents you ran (scaffolds, models, reasoning settings).


\begin{table}[t]
  \centering
  \caption{USACO Leaderboard (verbatim from the website).}
  \label{tab:usaco_full}
  \input{tables/usaco_full_results.tex}
\end{table}


\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.9\linewidth]{usaco_pareto_accuracy_vs_cost.pdf}
  \caption{Pareto frontier of accuracy vs.\ cost.}
  \label{fig:usaco_pareto}
\end{figure}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.9\linewidth]{usaco_total_tokens.pdf}
  \caption{Total completion tokens used per Agent}
  \label{fig:usaco_tokens}
\end{figure}

\begin{figure*}[t]
  \centering
  \adjustbox{max width=\textwidth, max height=0.9\textheight}{%
    \includegraphics{usaco_heatmap_best_vs_any.pdf}%
  }
  \caption{Heatmap: best-agent vs.\ any-agent success.}
  \label{fig:usaco_heatmap}
\end{figure*}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.9\linewidth]{usaco_accuracy_vs_release_date.pdf}
  \caption{Accuracy vs.\ model release date.}
  \label{fig:usaco_release}
\end{figure}

\clearpage